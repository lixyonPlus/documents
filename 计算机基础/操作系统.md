## MESI(Modified Exclusive Shared Or Invalid)缓存一致性协议
    - https://blog.csdn.net/MrYushiwen/article/details/123049838
### 数据在缓存中的4种状态
| 状态 | 描述 | 状态所在缓存对应的CPU是否独占数据 | cacheLine是否是最新数据 | 对数据的写入 | 
| :--: | :--: | :--: | :--: | :--: |
| M: 被修改（Modified) | 该缓存行只被缓存在该CPU的缓存中，并且是被修改过的（dirty),即与主存中的数据不一致，该缓存行中的数据需要在未来的某个时间点（允许其它CPU读取主存中相应数据之前）写回（write back）主存。当被写回主存之后，该缓存行的状态会变成独享（exclusive)状态。| 是 | 是 | 可以 |
| E: 独享的（Exclusive) | 该数据只被缓存在该CPU的缓存行中，它是未被修改过的（clean)，与主存中数据一致。该状态可以在任何时刻当有其它CPU读取该内存时变成共享状态（shared)。同样地，当CPU修改该缓存行中内容时，该状态可以变成Modified状态。| 是 | 是 | 可以 |
| S: 共享的（Shared) | 该状态意味着该数据可能被多个CPU缓存读取，并且各个缓存中的数据与主存数据一致（clean)，当有一个CPU修改自己的缓存行中的数据时，数据对应的缓存行状态变成Modified状态，其它CPU中该缓存行变成无效状态（Invalid）。| 否 | 是 | 可以  |
| I: 无效的（Invalid）| 该缓存是无效的（可能有其它CPU修改了该缓存行）。| 否 （无数据）| 无数据 | 无数据，不可以 |


### MESI的六种消息(请求消息和响应消息)
1. read：（请求消息）
    - “read” 消息用来获取指定物理地址上的 cache line(如果在缓存中，从缓存中取，不在缓存中则从内存中取) 数据。
2. read response：（响应消息）
    - "read response"消息包含先前“read”消息请求的数据。此“read response”消息可能来自内存或其他CPU的缓存。
3. invalidate：（请求消息）
    - Invalidate。该消息将其他 CPU cache 中指定的数据设置为失效。该消息携带物理地址，其他 CPU cache 在收到该消息后，必须进行匹配，发现在自己的 cache line 中有该地址的数据，那么就将其从 cahe line 中移除，并响应 Invalidate Acknowledge 回应。
4.  invalidate acknowledge：（响应消息）
    - 该消息用做回应Invalidate消息。
5. read invalidate：（请求消息）
    - 该消息中带有物理地址，用来说明想要读取哪一个 cache line 中的数据，同时指示其他缓存删除数据。可以看作是 read + Invalidate 消息的组合，“read invalidate”消息需要“read response”和一组“invalidate acknowledge”消息作为应答。
6. writeback：
    - “writeback”消息包含要写回内存的地址和数据（也可能是沿途“窥探”到其他cpu的缓存中）。该消息用在 modified 状态的 cache line 被置换时发出，用来将最新的数据写回 memory 或其他下一级 cache 中。

### MESI四种状态通过六种消息进行转换
![](https://img-blog.csdnimg.cn/5c815d5f825f4fde8a13e827ceb69618.png)

- a. cache 通过 writeback 将数据回写到 memory 或者下一级 cache 中。这时候状态由 modified 变成了 exclusive 。

- b. cpu 直接将数据写入 cache line ，导致状态变为了 modified 。

- c. CPU 收到一个 read invalidate 消息，该消息中带有物理地址，用来说明想要读取哪一个 cache line 中的数据，同时指示其他缓存删除数据。此时 CPU 必须将对应 cache line 设置成 invalid 状态 , 并且响应一个 read response 消息和 invalidate acknowledge 消息。

- d. CPU 需要执行一个原子的 readmodify-write 操作，并且其 cache 中没有缓存数据。这时候 CPU 就会在总线上发送一个 read invalidate 消息来请求数据，并试图独占该数据。CPU 可以通过收到的 read response 消息获取到数据，并等待所有的 invalidate acknowledge 消息，然后将状态设置为 modifie 。

- e. CPU需要执行一个原子的readmodify-write操作，并且其local cache中有read only的缓存数据（cacheline处于shared状态），这时候，CPU就会在总线上发送一个invalidate请求其他cpu清空自己的local copy，以便完成其独自霸占对该数据的所有权的梦想。同样的，该cpu必须收集所有其他cpu发来的invalidate acknowledge之后才能更改状态为 modified。

- f. 在本cpu独自享受独占数据的时候，其他的cpu发起read请求，希望获取数据，这时候，本cpu必须以其local cacheline的数据回应，并以read response回应之前总线上的read请求。这时候，本cpu失去了独占权，该cacheline状态从Modified状态变成shared状态（有可能也会进行写回的动作）。

- g. 这个迁移和f类似，只不过开始cacheline的状态是exclusive，cacheline和memory的数据都是最新的，不存在写回的问题。总线上的操作也是在收到read请求之后，以read response回应。

- h. 需要发送invalidate以通知其他cpu相应数据将要失效，并等待其他cpu的回应消息（invalidate acknowledge）。

- i. 其他的CPU进行一个原子的read-modify-write操作，但是，数据在本cpu的cacheline中，因此，其他的那个CPU会发送read invalidate，请求对该数据以及独占权。本cpu回送read response”和“invalidate acknowledge”，一方面把数据转移到其他cpu的cache中，另外一方面，清空自己的cacheline。

- j. cpu想要进行write的操作但是数据不在local cache中，因此，该cpu首先发送了read invalidate启动了一次总线transaction。在收到read response回应拿到数据，并且收集所有其他cpu发来的invalidate acknowledge之后（确保其他cpu没有local copy），完成整个bus transaction。当write操作完成之后，该cacheline的状态会从Exclusive状态迁移到Modified状态。

- k. 本CPU执行读操作，发现local cache没有数据，因此通过read发起一次bus transaction，来自其他的cpu local cache或者memory会通过read response回应，从而将该 cache line 从Invalid状态迁移到shared状态。

- l. 当cache line处于shared状态的时候，说明在多个cpu的local cache中存在副本，因此，这些cacheline中的数据都是read only的，一旦其中一个cpu想要执行数据写入的动作，必须先通过invalidate获取该数据的独占权，而其他的CPU会以invalidate acknowledge回应，清空数据并将其cacheline从shared状态修改成invalid状态。

### CPU的四种状态与操作系统的两种状态(用户态和内核态)
- CPU有四种状态，分别为编号为0(特权最大)到3(特权最小)，以及3个受保护的主要资源：内存、I/O端口和执行某些机器指令的能力。
- 操作系统它基于CPU之上，只用到了CPU的两种状态，一个内核态，一个用户态，内核态运行在CPU的第0等级，用户态运行在CPU的第3等级。
![](https://img-blog.csdnimg.cn/691ce9f3acc942aaa3f10cf668e8895a.png)

### 操作系统的用户态和内核态之间的切换
- 首先内核态与用户态是操作系统的两种运行级别,跟cpu没有必然的联系, cpu提供Ring0-Ring3三种级别的运行模式，Ring0级别最高，Ring3最低。其次Linux使用了Ring3级别运行用户态，Ring0作为 内核态，没有使用Ring1和Ring2。Ring3状态不能访问Ring0的地址空间（这里存放在整个内核的代码和所有的内核模块，以及内核所维护的数据）。然后用户运行一个程序，该程序所创建的进程开始是运行在用户态的，如果要执行文件操作，网络数据发送等操作，必须通过write，send等系统调用（比如netty和redis中对于多路复用select和poll的改进epoll也需要切换到内核态），这些系统调用会调用内核中的代码来完成操作，这时，必须切换到Ring0，然后进入内核地址空间去执行这些代码完成操作，完成后，切换回Ring3，回到用户态。这样，用户态的程序就不能随意操作内核地址空间，具有一定的安全保护作用。最后至于说保护模式，是说通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程的地址空间中的数据。

### 操作系统的用户态切换到内核态的四种情况
- 系统调用:这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如x86里的call gate也可以用来做系统调用，也能做到权限控制和内核代码保护，跟中断的效果完全一样，

- 硬中断:当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。该中断可被屏蔽。
从本质上讲，中断(硬)是一种电信号，当设备有某种事情发生的时候，他就会产生中断，通过总线把电信号发送给中断控制器。如果中断的线是激活的(与逻辑门的另外一边设置的是高电平，如果是低电平就进行了屏蔽)，中断控制器就把电信号发送给处理器的某个特定引脚。处理器于是立即停止自己正在做的事，跳到中断处理程序的入口点，进行中断处理。
- 软中断:软中断(softIRQ)的一种典型应用就是所谓的"下半部"（bottom half），它的得名来自于将硬件中断处理分离成"上半部"和"下半部"两个阶段的机制：上半部在屏蔽中断的上下文中运行，用于完成关键性的处理动作；而下半部则相对来说并不是非常紧急的，通常还是比较耗时的，因此由系统自行安排运行时机，不在中断服务上下文中执行。
在系统调用的时候，也可以用软中断的方式实现，比如fork() 实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h 中断。该中断不可被屏蔽。
- 异常:当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

### 内存分段
- 内存按访问的方式来看，就像长方形的带子，地址依次升高。内存是一个随机读写设备，即可以访问内部任何一处，不需要从头开始找，只要直接给出实际物理地址即可。分段是内存访问的机制，是给CPU用的访问内存的方式，只有CPU才会关注段,内存分段后，内存的地址（又称物理地址）就由两部分组成：段地址和段内偏移地址，段寄存器管理的是段地址。把内存分段后，每一个段就有一个段基址，段寄存器保存的就是这个段基址的高16位，这个16位的地址左移四位（后面加上4个0）就可构成20位的段基址。(这就是—— “段地址×16(或者左移四位)+偏移地址=物理地址”的寻址模式的由来。)，保护模式下，段(segmentation)强调的是分割，用来把内存分成不同的地址空间，每个段一个空间，而后通过CPU的MMU转换成实际物理地址。由于程序运行在不同的段里，根本上保护了CPU保护模式下的各个不相关的代码，所谓进程或者作业。

### 硬盘中的可执行文件加载到寄存器中进行运算的过程如下：
- 硬盘中的可执行文件（底层存储还是二进制的）加载到内存中，操作系统为其分配资源，变成了一个进程A，此时还没有跑起来；
- 过了一段时间之后，CPU0的时间片分配给了进程A，此时CPU0进行线程的装载，然后把需要用到的数据先从内存中读取到缓存中，读取的单元为一个缓存行，其大小现在通常为64字节（记住这个缓存行大小为64字节，这个非常重要，在后面会多次用到这个数值）。
- 然后数据再从缓存中读取到寄存器中，目前缓存一般为三级缓存，这里不具体画出。
- 寄存器得到了数据之后送去ALU（arithmetic and logic unit）做计算。

### 总线嗅探机制
在BUS总线上, 存在一个"总线嗅探机制",一旦某个线程共享变量被声明为volatile变量之后,一旦在某个线程中,修改了该共享变量值,就会向BUS总线发送一个共享变量改变的消息;CPU不停地嗅探BUS总线上的"共享变量改变的消息",一旦接收到该消息事件,就会将正在该CPU核心上执行的其它线程的工作内存的变量副本置为失效(Invalid)状态;之后该CPU核心会立刻向BUS总线发送一条消息,表示该线程中的副本变量已经失效;


### cpu访问时间
|cpu访问|大约需要的周期（cycle）	|大约需要的时间|
|:--:|:--:|:--:|
|寄存器|	1 cycle	|0ns|
|L1 Cache|	3—4 cycle	|1ns|
|L2 Cache|	10—20 cycle|	3ns|
|L3 Cache|	40—45 cycle	|15ns|
|内存	|	|60—90ns|

### 缓存行(Cache Line)有两个标志-脏（dirty）和有效（valid）,通常64字节。脏代表该数据和内存不一致。只有干净的数据才能被多个CacheLine共享。

### 伪共享
![](https://img-blog.csdnimg.cn/3f5b3f5aaeea45eeb19b4776bb3cf825.png)
多核多线程并发场景下，多个线程要操作的不同变量处于同一个缓存行中（64字节），某cpu更新缓存行的数据并写回缓存，同时其他处理器会使该缓存行失效，如需使用还要重新从内存中加载，这对效率有很大影响。
- 解决办法：
    - 缓存行填充
    - @Contended

### 为什么要使用Store Buffer
`如果CPU0发起一次对某个地址的写操作，但是其本地缓存中没有数据，这个数据存放在CPU1的本地缓存中。那么此时会进行如下操作：(缓存一致性协议MESI，具体的内容见笔者该篇文章：“了解高并发底层原理”，面试官：讲一下MESI（缓存一致性协议）吧)
根据MESI协议，在CPU缓存之间会进行如下沟通：`        
- 为了完成这次操作，CPU0会发出一个invalidate的信号，使其他CPU的cache数据无效（因为CPU0需要重新写这个地址中的值，说明这个地址中的值将被改变，如果不把其他CPU中存放的该地址的值无效，那么就有可能会出现数据不一致的问题）。
- CPU0的invalidate信号后，会等待其他CPU对于该信号的回复，即其他CPU需要回复invalidate acknowledge信号（消息）来告知CPU0我们已经接收到了invalidate信号，把cache数据变为无效的了。
- 而这个数据可能不只在CPU1的缓存中，还可能在CPU2、CPU3的缓存中，在所有CPU都回复给CPU0信号后才能真正发起写操作。
- 这个需要等待非常长的时间，这就导致了性能上的损耗。

### 加入了这个Store Buffer存储缓存区硬件结构后：
此时CPU0需要往某个地址中写入一个数据时：
- 它不需要去关心其他的CPU的local cache中有没有这个地址的数据，它只需要把它需要写的值直接存放到store buffer中，然后发出invalidate的信号。
- 等到其他CPU回复invalidate的信号后，再把CPU0存放在store buffer中的数据推到CPU0的本地缓存中。
- 这样就避免了CPU0等待其他CPU的响应了。
ps：每一个CPU core都拥有自己私有的store buffer，一个CPU只能访问自己私有的那个store buffer。

### 引入Invalidate Queue进一步优化
- store buffer的大小是有限的，所有的写入操作发生cache missing（数据不再本地）都会使用store buffer，因此store buffer很容易会满；
- 当store buffer满了之后，需要写数据的cpu还是会等待其他的CPU响应Invalidate信号以处理store buffer中的数据(即把store buffer中的数据推到CPU的本地缓存中)。
- 因此还是要回到其他CPU响应Invalidate信号上面来，其他CPU回复invalidate acknowledge信号（消息）来告知CPU0我们已经接收到了invalidate信号，把cache line数据变为无效的了。
- 如果一个CPU很忙，可能导致需要回复信号的cpu无法按时回复invalidate acknowledge信号（消息），这就可能会导致写入数据的cpu在等它回Invalidate ACK。
- 解决思路还是化同步为异步: cpu不必要处理了cache line之后才回Invalidate ACK，而是可以先将Invalid消息放到某个请求队列Invalid Queue，然后就返回Invalidate ACK。CPU可以后续再处理Invalid Queue中的消息，大幅度降低Invalidate ACK响应时间

### 操作系统底层的内存屏障是什么
- 完全内存屏障（full memory barrier）确保内存读和写操作；保障了内存屏障前的读写操作执行完毕、并且将结果提交到内存之后，再执行晚于屏障的读写操作。
- 内存读屏障（read memory barrier）仅确保了内存读操作；保障了内存屏障前的读操作执行完毕、并且将结果提交到内存之后，再执行晚于屏障的读操作。
- 内存写屏障(write memory barrier)仅保证了内存写操作。保障了内存屏障前的写操作执行完毕、并且将结果提交到内存之后，再执行晚于屏障的写操作。

### 为什么取余或取模计算结果有负数？为什么取余或取模操作没有&(与)操作快？
- 取余，遵循尽可能让商，即fixDiv方法向0靠近的原则；
- 取模，遵循尽可能让商，即floorDiv方法向负无穷靠近的原则
- 当除数和被除数符号相同时，结果相同；
- 当除数和被除数符号不相同时，有如下两种情况：
    - 为取模运算时，运算结果的符号和除数相同；
    - 为取余运算时，运算结果的符号和被除数相同。
不论是取模运算还是取余运算，当除数或被除数是负数时，那么计算结果也可能为负数。


### DMA
- DMA的英文拼写是“Direct Memory Access”，汉语的意思就是直接内存访问，是一种不经过CPU而直接从内存存取数据的数据交换模式。在DMA模式下，CPU只须向DMA控制器下达指令，让DMA控制器来处理数据的传送，数据传送完毕再把信息反馈给CPU，这样就很大程度上减轻了CPU资源占有率，可以大大节省系统资源。