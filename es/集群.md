### X-Pack Security配置
- 1.elasticsearch.yml 权限认证配置
```
xpack.security.enabled:true
```
- 2.运行密码设定的命令，设置ES内置用户及其初始密码:
```
bin/elasticsearch-setup-passwords interactive //同时设置elastic/kibina/三个用户的密码
```
- 3.kibana.yml 配置用户认证
```
elasticsearch.username: "kibana"
elasticsearch.password: "123456"
```
### 内部证书配置
- 1.生成证书
```
bin/elasticsearch-certutil ca //在elasticsearch目录下生成了elastic-stack-ca.p12文件
```
- 2.为群集中的节点生成证书和私钥
```
bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 ////在elasticsearch目录下生成了elastic-certificates.p12文件
```
- 3.elasticsearch.yml 配置证书
```
xpack.security.transport.ssl.enabled: true
xpack.security.transport.ssl.verification_mode: certificate
xpack.security.transport.ssl.keystore.path: certs/elastic-certificates.p12
xpack.security.transport.ssl.truststore.path: certs/elastic-certificates.p12
```
- 4.elasticsearch.yml 配置https
```
xpack.security.http.ssl.enabled: true
xpack.security.http.ssl.keystore.path: certs/elastic-certificates.p12
xpack.security.http.ssl.truststore.path: certs/elastic-certificates.p12
```
- 5.kibana连接es https
- 5.1 为kibana生成pem
```
openssl pkcs12 -in elastic-stack-ca.p12 -out newfile.crt.pem -clcerts -nokeys
```
- 5.2 kibana.yml 配置
```
elasticsearch.hosts: ["https://localhost:9200"]
elasticsearch.ssl.certificateAuthorities: [ "certs/newfile.crt.pem" ]
elasticsearch.ssl.verificationMode: none
```
- 6.kibana配置https
- 6.1.es中生成ca文件(解压包含了instance.crt和instance.key)
```
bin/elasticsearch-certutil ca --pem
```
- 6.2 kibana.yml 配置
```
server.ssl.enabled: true
server.ssl.certificate: config/certs/instance.crt
server.ssl.key: config/certs/instance.key
```
- 7 fielbeat配置通过https访问es
```
bin/elasticsearch-certutil cert --pem elastic-stack-ca.p12
```
将生成的certificate-bundle.zip解压得到 ca.crt
- 7.1 fielbeat.yml配置
```
output.elasticsearch:
  hosts: ["localhost:9200"]
  protocol: "https"
  ssl.verification_mode: none
  ssl.certificate_authorities: ["certs/ca.crt"]
  username: "elastic"
  password: "123456"
```
---

# Hot&Warm架构&Shard Filtering
 数据通常不会有 Update 操作;适用于 Time based 索引数据(生命周期管理)，同时数据量比较大的场景，引入Warm节点，低配置大容量的机器存放老数据，以降低部署成本
 Hot 节点(通常使用 SSD):索引有不断有新文档写入。通常使用 SSD
 Warm 节点(通常使用 HDD):索引不存在新数据的写入;同时也不存在大量的数据查询
```
node.attr.my_node_type=hot ### 标记该节点类型为hot
```
```
node.attr.my_node_type=warm ### 标记该节点类型为warm
```
### 配置索引存储到指定的节点
```
PUT _index
{
  "settings":{
    "index.routing.allocation.require.my_node_type":"hot/warm"
  }
}
```
# Rack Awareness
ES的节点可能分布在不同的机架，当一个机架断电，可能会同时丢失几个节点，如果一个索引相同的主分片和副本分片，同时在这个机架上，就有可能导致数据的丢失
通过Rack Awareness 的机制， 就可以尽可能避免将同一个索引的主副分片同时分配在一个机架的节点上
### 标记节点机架
```
node.attr.rack_id=rack1 ### 标记该节点属于rack1机架
```
### 注意：当设置了分片分布属性时，如果集群中的节点没有设置其中任何一个属性，那么分片就不会分布到这个节点中。 
```
PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.awareness.attributes": "rack_id", ### 设置rack_id作为集群分片分布规则的一个属性(在所有节点都要设置)
    "cluster.routing.allocation.awareness.force.rack_id.values": "rack1,rack2" ### 分布强制分布在标记了rack_id=rack1,rack2的节点上
  }
}
```

